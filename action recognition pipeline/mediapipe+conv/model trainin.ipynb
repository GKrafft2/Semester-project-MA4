{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "PATH = \"data/\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normailze the data over x,y and z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_x_y_z_mean_and_std(array):\n",
    "    \"\"\"Returns list of means and stds for each channel of the array.\"\"\"\n",
    "    means = []\n",
    "    stds = []\n",
    "    for i in range(3):\n",
    "        channel = array[:,:,i]\n",
    "        mean = np.mean(channel)\n",
    "        std = np.std(channel)\n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "    return means, stds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the dataset mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_mean = np.empty((1,3))\n",
    "general_std = np.empty((1,3))\n",
    "\n",
    "for folder in os.listdir(PATH):\n",
    "    for file in os.listdir(PATH+folder):\n",
    "        array = np.load(PATH+folder+\"/\"+file, allow_pickle=True)\n",
    "        array = np.clip(array, -10, 10)\n",
    "        means, stds = compute_x_y_z_mean_and_std(array)\n",
    "        general_mean = np.append(general_mean, np.array([means]), axis=0)\n",
    "        general_std = np.append(general_std, np.array([stds]), axis=0)\n",
    "        # print(folder, file, means, stds)\n",
    "\n",
    "dataset_mean = np.nanmean(general_mean, axis=0)\n",
    "dataset_std = np.nanstd(general_std, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+000, 1.32038950e-311, 0.00000000e+000],\n",
       "       [9.94667958e-002, 3.55457854e-001, 1.88731478e-001],\n",
       "       [1.70998945e-001, 3.48339452e-001, 1.37660975e-001],\n",
       "       [1.40657750e-001, 3.05853073e-001, 1.32741264e-001],\n",
       "       [1.71437179e-001, 3.42695885e-001, 1.88092242e-001],\n",
       "       [1.60883992e-001, 3.15836185e-001, 1.37447132e-001],\n",
       "       [1.58759836e-001, 3.52427005e-001, 1.59663127e-001],\n",
       "       [2.28214156e-001, 3.77174644e-001, 1.89980709e-001],\n",
       "       [1.77607109e-001, 3.30737086e-001, 1.42986202e-001],\n",
       "       [1.36107215e-001, 3.48227022e-001, 1.83390277e-001],\n",
       "       [1.84334273e-001, 3.72180160e-001, 1.68591201e-001],\n",
       "       [1.52823033e-001, 3.12916589e-001, 1.24395230e-001],\n",
       "       [2.02880749e-001, 3.92977509e-001, 1.92105367e-001],\n",
       "       [1.92944947e-001, 3.81183652e-001, 1.54981471e-001],\n",
       "       [1.31778797e-001, 3.06254332e-001, 1.32971832e-001],\n",
       "       [1.61158503e-001, 3.27881835e-001, 1.70968550e-001],\n",
       "       [8.19819493e-002, 3.02941925e-001, 1.59347757e-001],\n",
       "       [1.57607206e-001, 3.23824741e-001, 1.62428254e-001],\n",
       "       [9.65465971e-002, 2.90382141e-001, 1.58107336e-001],\n",
       "       [1.63363901e-001, 3.23712508e-001, 1.57361210e-001],\n",
       "       [1.41428532e-001, 3.19032512e-001, 1.51981360e-001],\n",
       "       [3.43637565e-001, 4.33354288e-001, 2.42865835e-001],\n",
       "       [1.79760114e-001, 3.71383707e-001, 1.30946515e-001],\n",
       "       [1.13938723e-001, 3.01767366e-001, 1.61091050e-001],\n",
       "       [1.67372803e-001, 3.83049792e-001, 1.87161092e-001],\n",
       "       [1.59874782e-001, 3.16908666e-001, 1.39465642e-001],\n",
       "       [1.22903789e-001, 2.68716569e-001, 1.61945317e-001],\n",
       "       [1.78565086e-001, 2.98902508e-001, 1.77369753e-001],\n",
       "       [3.25094365e-001, 4.08195721e-001, 2.01648530e-001],\n",
       "       [1.98343606e-001, 4.29889177e-001, 3.14048251e-001],\n",
       "       [1.32025929e-001, 3.39013949e-001, 1.45304402e-001],\n",
       "       [1.65280304e-001, 3.96412824e-001, 1.88515231e-001],\n",
       "       [1.83651204e-001, 3.76642870e-001, 1.35863044e-001],\n",
       "       [1.35934476e-001, 3.55783327e-001, 1.90910725e-001],\n",
       "       [1.15756815e-001, 2.78410428e-001, 1.20672585e-001],\n",
       "       [1.27484255e-001, 2.95931255e-001, 1.36662258e-001],\n",
       "       [3.81494979e-001, 4.09397557e-001, 2.09685723e-001],\n",
       "       [1.19457327e-001, 3.00505565e-001, 1.47992724e-001],\n",
       "       [1.71679925e-001, 3.94688054e-001, 2.26969716e-001],\n",
       "       [1.80457701e-001, 3.55216108e-001, 1.47830606e-001],\n",
       "       [1.93141471e-001, 4.00036758e-001, 2.09407327e-001],\n",
       "       [1.07747169e-001, 3.45553498e-001, 1.71554946e-001],\n",
       "       [1.46970720e-001, 3.28584120e-001, 1.27002605e-001],\n",
       "       [1.33257028e-001, 3.30097327e-001, 1.59943491e-001],\n",
       "       [1.25525956e-001, 3.05960372e-001, 1.35986063e-001],\n",
       "       [1.66992320e-001, 3.36464867e-001, 1.57403390e-001],\n",
       "       [2.83897781e-001, 4.05791599e-001, 1.58913868e-001],\n",
       "       [1.01631723e-001, 2.98509753e-001, 1.34047884e-001],\n",
       "       [1.74438122e-001, 3.68481824e-001, 1.98517988e-001],\n",
       "       [1.31152934e-001, 3.35219402e-001, 1.57375282e-001],\n",
       "       [1.05988830e-001, 2.97697959e-001, 1.40411054e-001],\n",
       "       [1.57150267e-001, 3.61688402e-001, 2.03705653e-001],\n",
       "       [1.20672033e-001, 3.55290156e-001, 1.51497528e-001],\n",
       "       [1.42763507e-001, 3.23604355e-001, 1.10464218e-001],\n",
       "       [3.81820968e-001, 4.34945132e-001, 2.25452998e-001],\n",
       "       [1.62003575e-001, 3.30089678e-001, 1.12979775e-001],\n",
       "       [1.25496980e-001, 3.24769227e-001, 1.63450373e-001],\n",
       "       [1.34943997e-001, 3.30873026e-001, 1.66906341e-001],\n",
       "       [1.72317408e-001, 3.79201125e-001, 2.11453930e-001],\n",
       "       [1.84849321e-001, 4.13696905e-001, 2.22417132e-001],\n",
       "       [1.57895463e-001, 3.36756208e-001, 1.01111054e-001],\n",
       "       [1.72419210e-001, 4.54428328e-001, 2.74649925e-001],\n",
       "       [1.18653688e-001, 3.34686517e-001, 1.60433717e-001],\n",
       "       [1.77807129e-001, 3.35585843e-001, 1.62551486e-001],\n",
       "       [2.10879091e-001, 3.60934545e-001, 2.39233561e-001],\n",
       "       [1.62176398e-001, 3.36692123e-001, 1.83667098e-001],\n",
       "       [1.33795245e-001, 2.94777640e-001, 1.33899440e-001],\n",
       "       [1.26628915e-001, 2.85273411e-001, 1.55379204e-001],\n",
       "       [1.50341072e-001, 3.52980108e-001, 1.84638739e-001],\n",
       "       [1.67410132e-001, 4.38542754e-001, 2.57946345e-001],\n",
       "       [1.64524288e-001, 3.68200577e-001, 1.82808745e-001],\n",
       "       [1.95910782e-001, 3.60336195e-001, 2.18484085e-001],\n",
       "       [1.88541269e-001, 3.59026615e-001, 1.86333287e-001],\n",
       "       [2.67547775e-001, 4.08673894e-001, 2.34430743e-001],\n",
       "       [1.64288149e-001, 3.71583940e-001, 1.64349090e-001],\n",
       "       [1.68139147e-001, 4.17691486e-001, 2.21689544e-001],\n",
       "       [2.08881089e-001, 3.56799504e-001, 1.52086218e-001],\n",
       "       [1.79240647e-001, 3.71623063e-001, 1.67152217e-001],\n",
       "       [1.68259895e-001, 4.27858232e-001, 2.21116898e-001],\n",
       "       [2.46303566e-001, 4.52929094e-001, 2.78554459e-001],\n",
       "       [1.92188465e-001, 3.57004189e-001, 1.41022192e-001],\n",
       "       [1.62077606e-001, 3.47725667e-001, 1.80451144e-001],\n",
       "       [1.15054194e-001, 2.95238253e-001, 1.41157503e-001],\n",
       "       [1.36754517e-001, 3.10809527e-001, 1.55398111e-001],\n",
       "       [1.61284513e-001, 4.10970896e-001, 2.42709795e-001],\n",
       "       [1.53728970e-001, 3.75827033e-001, 2.05716453e-001],\n",
       "       [2.39637665e-001, 3.75386226e-001, 2.50245159e-001],\n",
       "       [2.26667276e-001, 4.46613615e-001, 2.90898725e-001],\n",
       "       [1.79273350e-001, 4.44186649e-001, 2.56823598e-001],\n",
       "       [1.39447892e-001, 3.31341946e-001, 1.55405976e-001],\n",
       "       [1.18576100e-001, 3.37553062e-001, 1.80472358e-001],\n",
       "       [1.55329616e-001, 3.99081172e-001, 2.22633161e-001],\n",
       "       [1.34652659e-001, 4.03308161e-001, 2.28987553e-001],\n",
       "       [1.05212911e-001, 3.45610130e-001, 1.71876246e-001],\n",
       "       [8.36616869e-002, 3.22077666e-001, 1.67859137e-001],\n",
       "       [1.63168153e-001, 3.41378504e-001, 2.23450117e-001],\n",
       "       [1.69158165e-001, 3.81743423e-001, 2.00721635e-001],\n",
       "       [1.84826743e-001, 3.69803207e-001, 2.29785299e-001],\n",
       "       [1.37522470e-001, 3.26489746e-001, 1.64271297e-001],\n",
       "       [1.58727052e-001, 4.11736912e-001, 2.25028504e-001],\n",
       "       [1.24589407e-001, 3.64985346e-001, 1.85792581e-001],\n",
       "       [1.42804658e-001, 3.49799385e-001, 2.21208316e-001],\n",
       "       [1.09143508e-001, 3.16324177e-001, 1.34631960e-001],\n",
       "       [1.05424707e-001, 3.33066873e-001, 1.92925757e-001],\n",
       "       [1.18270691e-001, 3.08305435e-001, 1.49634278e-001],\n",
       "       [7.40363413e-002, 3.11208370e-001, 1.49314106e-001],\n",
       "       [1.46066176e-001, 3.44921415e-001, 1.95540420e-001],\n",
       "       [1.01324857e-001, 3.73790972e-001, 2.37604132e-001],\n",
       "       [1.76414508e-001, 3.84143471e-001, 2.23484064e-001],\n",
       "       [1.29931308e-001, 3.80985337e-001, 1.94611161e-001],\n",
       "       [9.35344124e-002, 3.78807734e-001, 2.38911748e-001],\n",
       "       [1.82628396e-001, 4.15965309e-001, 2.72274988e-001],\n",
       "       [1.24162081e-001, 3.24716332e-001, 1.66607630e-001],\n",
       "       [1.37968149e-001, 3.77311836e-001, 2.56474328e-001],\n",
       "       [1.17793945e-001, 3.33431228e-001, 1.70256776e-001],\n",
       "       [1.08382741e-001, 3.12741819e-001, 1.50050794e-001],\n",
       "       [1.87936610e-001, 3.46969149e-001, 1.61578813e-001],\n",
       "       [1.15810447e-001, 3.24080837e-001, 1.27998658e-001],\n",
       "       [1.18643879e-001, 3.68252892e-001, 2.08834046e-001]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come\n",
      "lie down\n",
      "sit\n",
      "stay\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(PATH):\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder, dataset_mean, dataset_std):\n",
    "        self.dataset = []\n",
    "        self.labels = []\n",
    "        label_dict = {\"come\":0,\"lie down\":1,\"sit\":2,\"stay\":3}\n",
    "        \n",
    "        for folder in os.listdir(data_folder):\n",
    "            for file in os.listdir(data_folder + folder):\n",
    "                data = np.load(os.path.join(data_folder, folder, file))\n",
    "                # normalize data\n",
    "                data[:,:,0] = (data[:,:,0] - dataset_mean[0])/dataset_std[0]\n",
    "                data[:,:,1] = (data[:,:,1] - dataset_mean[1])/dataset_std[1]\n",
    "                data[:,:,2] = (data[:,:,2] - dataset_mean[2])/dataset_std[2]\n",
    "                self.dataset.append(data)\n",
    "                self.labels.append(label_dict[folder])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset[index]\n",
    "        data = np.transpose(data, (2, 0, 1))\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return torch.tensor(data).float(), torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 9, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.zeros(16, 3, 18,5)\n",
    "maxpool = nn.MaxPool2d(2)(test)\n",
    "maxpool.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=3, n_output=4):\n",
    "        super().__init__()\n",
    "    \n",
    "        # input = 75x20x3\n",
    "        self.conv1 = nn.Conv2d(n_input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # input = 37x10x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # input = 18x5x64\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # input = 9x2x128\n",
    "        self.fc1 = nn.Linear(128*9*2, 512)\n",
    "        self.fc2 = nn.Linear(512, n_output)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2) #maxpool of kernel size 2 to reduce the size of the images by a factor 2\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128*9*2) #flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the necessary hyperparameters\n",
    "batch_size = 4\n",
    "# learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "num_classes = 4\n",
    "\n",
    "# Set the path to your data folder\n",
    "data_folder = PATH  # Replace with the actual path to your data folder\n",
    "\n",
    "# Create an instance of the dataset\n",
    "dataset = CustomDataset(data_folder, dataset_mean, dataset_std)\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "\n",
    "\n",
    "# Specify the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Create an instance of the CNN model and move it to the device\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce RTX 4070 Ti', major=8, minor=9, total_memory=12281MB, multi_processor_count=60)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Training => Loss: 1.2624 | Train Accuracy: 0.2966\n",
      "Epoch 2/20\n",
      "Training => Loss: 0.7586 | Train Accuracy: 0.6695\n",
      "Epoch 3/20\n",
      "Training => Loss: 0.5290 | Train Accuracy: 0.6949\n",
      "Epoch 4/20\n",
      "Training => Loss: 0.3645 | Train Accuracy: 0.7373\n",
      "Epoch 5/20\n",
      "Training => Loss: 0.3649 | Train Accuracy: 0.7119\n",
      "Epoch 6/20\n",
      "Training => Loss: 0.2280 | Train Accuracy: 0.7797\n",
      "Epoch 7/20\n",
      "Training => Loss: 0.2059 | Train Accuracy: 0.7627\n",
      "Epoch 8/20\n",
      "Training => Loss: 0.1656 | Train Accuracy: 0.7712\n",
      "Epoch 9/20\n",
      "Training => Loss: 0.1274 | Train Accuracy: 0.7881\n",
      "Epoch 10/20\n",
      "Training => Loss: 0.0923 | Train Accuracy: 0.7881\n",
      "Epoch 11/20\n",
      "Training => Loss: 0.0520 | Train Accuracy: 0.8051\n",
      "Epoch 12/20\n",
      "Training => Loss: 0.0430 | Train Accuracy: 0.8051\n",
      "Epoch 13/20\n",
      "Training => Loss: 0.0370 | Train Accuracy: 0.8051\n",
      "Epoch 14/20\n",
      "Training => Loss: 0.0345 | Train Accuracy: 0.8051\n",
      "Epoch 15/20\n",
      "Training => Loss: 0.0185 | Train Accuracy: 0.8051\n",
      "Epoch 16/20\n",
      "Training => Loss: 0.0157 | Train Accuracy: 0.8051\n",
      "Epoch 17/20\n",
      "Training => Loss: 0.0170 | Train Accuracy: 0.8051\n",
      "Epoch 18/20\n",
      "Training => Loss: 0.0106 | Train Accuracy: 0.8051\n",
      "Epoch 19/20\n",
      "Training => Loss: 0.0120 | Train Accuracy: 0.8051\n",
      "Epoch 20/20\n",
      "Training => Loss: 0.0089 | Train Accuracy: 0.8051\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    num_correct = 0\n",
    "    running_epoch_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred = outputs.argmax(dim = -1)\n",
    "\n",
    "        num_correct += (y_pred == labels).sum().item()\n",
    "        running_epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_epoch_loss / len(train_loader)\n",
    "    epoch_acc = num_correct / len(train_loader.dataset)\n",
    "\n",
    "    print(f'Training => Loss: {epoch_loss:.4f} | Train Accuracy: {epoch_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.96%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs , labels in validation_loader:\n",
    "        # Move data to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get predicted labels\n",
    "        y_pred = outputs.argmax(dim = -1)\n",
    "\n",
    "        # Update total and correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (y_pred == labels).sum().item()\n",
    "\n",
    "    # Print accuracy\n",
    "    print('Test Accuracy: {:.2f}%'.format(100 * correct / total))\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'trained_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a1eca162d8244ec663334057c1610a3bae01391a28d85af84dac413dee83203"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
