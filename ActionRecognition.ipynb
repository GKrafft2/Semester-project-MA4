{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data( name, data_path = DATA_PATH):\n",
    "# label = 0: roll_droite, 1: roll_gauche, 2: salut_droite, 3: salut_gauche (determinÃ© apar l'ordre des pkl dans le dossier data)\n",
    "    master_df = pd.DataFrame(columns = [\"frame\",\"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\", \"label\"])\n",
    "    label = 0\n",
    "    for pickle_file in os.listdir(DATA_PATH):\n",
    "        if pickle_file.endswith(name+\".pkl\"):\n",
    "            temp_df = pd.read_pickle(DATA_PATH + pickle_file)\n",
    "            temp_df[\"label\"] = label\n",
    "            label += 1\n",
    "            master_df = pd.concat([master_df, temp_df], axis = 0)\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat([get_data(\"gui\"), get_data(\"val\")], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = master_df[[\"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min max normalization per angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df[[\"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\"]] = (temp_df-temp_df.min())/(temp_df.max()-temp_df.min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop nan to avoid instability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, window_size):\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        n_vids = 8 #number of videos - we cannot take frames that are not in the same video\n",
    "        return len(self.df) - self.window_size*n_vids + 2*n_vids\n",
    "\n",
    "    def __getitem__(self, idx): #for now we take window_size consecutive frames\n",
    "        labels = self.df.iloc[idx:idx+self.window_size, 5].values\n",
    "        same = True\n",
    "        for label in labels:\n",
    "            if label != labels[0]:\n",
    "                same = False\n",
    "        if same == False:\n",
    "            return self.__getitem__(idx+1) #if the labels are not the same, we skip this window\n",
    "        else:\n",
    "            label = labels[0]\n",
    "        \n",
    "        data = self.df.iloc[idx:idx+self.window_size, 1:5].values\n",
    "        # data = (data-data.mean(axis=0))/data.std(axis=0)\n",
    "        return torch.tensor(data).float(), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "window_size = 5\n",
    "df = master_df\n",
    "dataset = TimeSeriesDataset(df, window_size)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.batch_norm = nn.BatchNorm1d(input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # = self.batch_norm(x)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = torch.nn.functional.softmax(self.fc(out[:, -1, :]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1831"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliot\\AppData\\Local\\Temp\\ipykernel_23288\\597975006.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = torch.nn.functional.softmax(self.fc(out[:, -1, :]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training => Loss: 1.0888 | Accuracy: 0.6683\n",
      "Training => Loss: 0.9306 | Accuracy: 0.8203\n",
      "Training => Loss: 0.9194 | Accuracy: 0.8253\n",
      "Training => Loss: 0.9149 | Accuracy: 0.8285\n",
      "Training => Loss: 0.9124 | Accuracy: 0.8318\n",
      "Training => Loss: 0.9116 | Accuracy: 0.8315\n",
      "Training => Loss: 0.9106 | Accuracy: 0.8324\n",
      "Training => Loss: 0.9083 | Accuracy: 0.8335\n",
      "Training => Loss: 0.9084 | Accuracy: 0.8327\n",
      "Training => Loss: 0.9074 | Accuracy: 0.8341\n",
      "Training => Loss: 0.9083 | Accuracy: 0.8318\n",
      "Training => Loss: 0.9063 | Accuracy: 0.8363\n",
      "Training => Loss: 0.9060 | Accuracy: 0.8361\n",
      "Training => Loss: 0.9038 | Accuracy: 0.8380\n",
      "Training => Loss: 0.9032 | Accuracy: 0.8382\n",
      "Training => Loss: 0.9042 | Accuracy: 0.8354\n",
      "Training => Loss: 0.9016 | Accuracy: 0.8395\n",
      "Training => Loss: 0.9013 | Accuracy: 0.8390\n",
      "Training => Loss: 0.9000 | Accuracy: 0.8412\n",
      "Training => Loss: 0.8991 | Accuracy: 0.8412\n"
     ]
    }
   ],
   "source": [
    "input_size = 4 # Size of each time step in the input window\n",
    "hidden_size = 64 # Number of features in the hidden state of the LSTM\n",
    "num_layers = 2 # Number of LSTM layers\n",
    "num_classes = 4 # Number of output classes (i.e. number of possible labels)\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 20\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Record the number of correct predictions and total loss\n",
    "\n",
    "\n",
    "debug = False\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    num_correct = 0\n",
    "    running_epoch_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # print(inputs)\n",
    "        # print(i)\n",
    "        # print(outputs)\n",
    "        # print(labels)\n",
    "\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print(outputs)\n",
    "\n",
    "        y_pred = outputs.argmax(dim = -1)\n",
    "\n",
    "        if debug:\n",
    "            # print(f\"predicted labesl = {y_pred}\")\n",
    "            # print(f\"true labels = {labels}\")\n",
    "            print(f\"correct = {(y_pred == labels).sum().item()}\")\n",
    "\n",
    "        num_correct += (y_pred == labels).sum().item()\n",
    "        running_epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_epoch_loss / len(dataloader)\n",
    "    epoch_acc = num_correct / len(dataloader.dataset)\n",
    "    print(f'Training => Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 4])\n",
      "tensor([2, 0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataloader:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1460, 0.2625, 0.9405, 0.2407],\n",
       "        [0.1467, 0.2676, 0.9486, 0.1800],\n",
       "        [0.1398, 0.2688, 0.9595, 0.1429],\n",
       "        [0.1324, 0.2731, 0.9608, 0.1297],\n",
       "        [0.1346, 0.2773, 0.9588, 0.1440]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliot\\AppData\\Local\\Temp\\ipykernel_23288\\597975006.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = torch.nn.functional.softmax(self.fc(out[:, -1, :]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2], device='cuda:0')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x[0,:,:].unsqueeze(0).to(device)).argmax(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 2, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a1eca162d8244ec663334057c1610a3bae01391a28d85af84dac413dee83203"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
